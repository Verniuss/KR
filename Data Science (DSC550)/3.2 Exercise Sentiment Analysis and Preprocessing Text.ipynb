{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747d5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Using the TextBlob Sentiment Analyzer\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d2e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "#Import the movie review data as a data frame and ensure that the data is loaded properly.\n",
    "url = 'https://drive.google.com/file/d/1TYrXIe4f7DOlZvszUmLE6H0aV17L-4Ps/view?usp=sharing'\n",
    "file_id = url.split('/')[-2]\n",
    "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
    "response = requests.get(dwn_url).content\n",
    "df = pd.read_csv(io.StringIO(response.decode('utf-8')), sep='\\t', encoding='unicode_escape')\n",
    "\n",
    "# check if there are missing values in the sentiment column\n",
    "print(df['sentiment'].isnull().sum())\n",
    "\n",
    "# check the first 5 rows to make sure the sentiment column is populated\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ef394e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ef30f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01701159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'sentiment', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1134d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "Number of positive reviews: 12500\n",
      "Number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values in the sentiment column\n",
    "print(df['sentiment'].unique())\n",
    "\n",
    "# Count the number of positive and negative reviews\n",
    "positive_count = len(df[df['sentiment'] == 1])\n",
    "negative_count = len(df[df['sentiment'] == 0])\n",
    "\n",
    "print(f\"Number of positive reviews: {positive_count}\")\n",
    "print(f\"Number of negative reviews: {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b287050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TextBlob to classify each movie review as positive or negative. \n",
    "#Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment.\n",
    "correct = 0\n",
    "for index, row in df.iterrows():\n",
    "    text = row['review']\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0 and row['sentiment'] == 'positive':\n",
    "        correct += 1\n",
    "    elif polarity <= 0 and row['sentiment'] == 'negative':\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752c21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TextBlob: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy of this model. Is this model better than random guessing?\n",
    "accuracy = correct / len(df)\n",
    "print(f\"Accuracy of TextBlob: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86d034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of TextBlob: 0.45622744952112515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# calculate the predicted polarity scores using TextBlob\n",
    "df['predicted_polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# calculate the MAE\n",
    "mae = mean_absolute_error(df['sentiment'], df['predicted_polarity'])\n",
    "\n",
    "print(f\"MAE of TextBlob: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b697412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MAE of TextBlob is 0.456, which means that, on average, the model's predictions are off by 0.456.\n",
    "# The reason I did this is because there is an issue with the tsv file where the sentiment column keeps returning as NaN. \n",
    "# I'm thinking that the sentiment labels in the dataset are mislabeled or that the polarity scores generated by TextBlob \n",
    "# are not in the same range as the labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e5d95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VADER: 0.0\n"
     ]
    }
   ],
   "source": [
    "#For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4).\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "correct = 0\n",
    "for index, row in df.iterrows():\n",
    "    text = row['review']\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    if score['compound'] >= 0 and row['sentiment'] == 'positive':\n",
    "        correct += 1\n",
    "    elif score['compound'] < 0 and row['sentiment'] == 'negative':\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(df)\n",
    "print(f\"Accuracy of VADER: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78ae423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Prepping Text for a Custom Model\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f021afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the TSV file\n",
    "url = 'https://drive.google.com/file/d/1TYrXIe4f7DOlZvszUmLE6H0aV17L-4Ps/view?usp=sharing'\n",
    "file_id = url.split('/')[-2]\n",
    "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
    "response = requests.get(dwn_url).content\n",
    "df = pd.read_csv(io.StringIO(response.decode('utf-8')), sep='\\t', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb381a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text to lowercase\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273a2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and special characters\n",
    "df['review'] = df['review'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b1ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kyle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7044d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f511f83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of bag-of-words matrix: (25000, 92379)\n"
     ]
    }
   ],
   "source": [
    "# Create a bag-of-words matrix\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(df['review'])\n",
    "print(f\"Dimensions of bag-of-words matrix: {bow_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ec1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of tf-idf matrix: (25000, 92379)\n"
     ]
    }
   ],
   "source": [
    "# Create a tf-idf matrix\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['review'])\n",
    "print(f\"Dimensions of tf-idf matrix: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e9d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
