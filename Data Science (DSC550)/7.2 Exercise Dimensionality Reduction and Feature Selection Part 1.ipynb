{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2c8675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape   \n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg  \\\n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold   \n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2  \\\n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "#1 Import the housing data as a data frame and ensure that the data is loaded properly.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv('https://drive.google.com/uc?id=1w0zihl-UPGytbd25Yr2g8g7cA8Fe_N_B')\n",
    "\n",
    "# Check that the data is loaded properly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0897c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour   \n",
      "0          60       RL         65.0     8450   Pave      Reg         Lvl  \\\n",
      "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
      "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
      "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
      "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
      "\n",
      "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch   \n",
      "0    AllPub    Inside       Gtl  ...             0         0           0  \\\n",
      "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
      "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
      "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "\n",
      "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
      "0        0       0       2    2008        WD         Normal    208500  \n",
      "1        0       0       5    2007        WD         Normal    181500  \n",
      "2        0       0       9    2008        WD         Normal    223500  \n",
      "3        0       0       2    2006        WD        Abnorml    140000  \n",
      "4        0       0      12    2008        WD         Normal    250000  \n",
      "\n",
      "[5 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "#2 Drop the \"Id\" column and any features that are missing more than 40% of their values. (continued)\n",
    "\n",
    "# Drop the \"Id\" column\n",
    "df.drop(\"Id\", axis=1, inplace=True)\n",
    "\n",
    "# Drop features with more than 40% missing values\n",
    "missing_perc = df.isnull().sum() / len(df)\n",
    "drop_cols = missing_perc[missing_perc > 0.4].index\n",
    "df.drop(drop_cols, axis=1, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a5bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#3 For numerical columns, fill in any missing data with the median value.\n",
    "\n",
    "# Fill missing numerical values with the median\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2137c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#4 For categorical columns, fill in any missing data with the most common value (mode).\n",
    "\n",
    "# Fill missing categorical values with the mode\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebcfa222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt   \n",
      "0          60         65.0     8450            7            5       2003  \\\n",
      "1          20         80.0     9600            6            8       1976   \n",
      "2          60         68.0    11250            7            5       2001   \n",
      "3          70         60.0     9550            7            5       1915   \n",
      "4          60         84.0    14260            8            5       2000   \n",
      "\n",
      "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw   \n",
      "0          2003       196.0         706           0  ...           False  \\\n",
      "1          1976         0.0         978           0  ...           False   \n",
      "2          2002       162.0         486           0  ...           False   \n",
      "3          1970         0.0         216           0  ...           False   \n",
      "4          2000       350.0         655           0  ...           False   \n",
      "\n",
      "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml   \n",
      "0         False         False         True                  False  \\\n",
      "1         False         False         True                  False   \n",
      "2         False         False         True                  False   \n",
      "3         False         False         True                   True   \n",
      "4         False         False         True                  False   \n",
      "\n",
      "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family   \n",
      "0                  False                 False                 False  \\\n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                  True                  False  \n",
      "1                  True                  False  \n",
      "2                  True                  False  \n",
      "3                 False                  False  \n",
      "4                  True                  False  \n",
      "\n",
      "[5 rows x 267 columns]\n"
     ]
    }
   ],
   "source": [
    "#5 Convert the categorical columns to dummy variables.\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad9329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "#6 Split the data into a training and test set, where the SalePrice column is the target.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training and test set\n",
    "X = df.drop(\"SalePrice\", axis=1)\n",
    "y = df[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9fabb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-value: 0.8890\n",
      "RMSE: 27827.3650\n"
     ]
    }
   ],
   "source": [
    "#7 Run a linear regression and report the R2-value and RMSE on the test set.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Run a linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"R2-value: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b966df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the PCA-transformed matrix: 1\n"
     ]
    }
   ],
   "source": [
    "#8 Fit and transform the training features with a PCA so that 90% of the variance is retained.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit and transform the training features with PCA\n",
    "pca = PCA(n_components=0.9, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "print(f\"Number of features in the PCA-transformed matrix: {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0a48ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in PCA-transformed matrix: 1\n"
     ]
    }
   ],
   "source": [
    "#9 How many features are in the PCA-transformed matrix?\n",
    "print(\"Number of features in PCA-transformed matrix:\", X_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57eeed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Transform but DO NOT fit the test features with the same PCA.\n",
    "\n",
    "# Transform but DO NOT fit the test features with PCA\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd662a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-value on PCA-transformed data: 0.0669\n",
      "RMSE on PCA-transformed data: 80692.3887\n"
     ]
    }
   ],
   "source": [
    "#11 Repeat step 7 with your PCA transformed data.\n",
    "# Run a linear regression on PCA-transformed data\n",
    "model_pca = LinearRegression()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate the model on PCA-transformed test data\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "rmse_pca = mean_squared_error(y_test, y_pred_pca, squared=False)\n",
    "print(f\"R2-value on PCA-transformed data: {r2_pca:.4f}\")\n",
    "print(f\"RMSE on PCA-transformed data: {rmse_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907124e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 Take your original training features (from step 6) and apply a min-max scaler to them.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply min-max scaler to the original training features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c11053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high variance features: 47\n"
     ]
    }
   ],
   "source": [
    "#13 Find the min-max scaled features in your training set that have a variance above 0.1.\n",
    "\n",
    "from numpy import var, where\n",
    "\n",
    "# Find the min-max scaled features in the training set that have a variance above 0.1\n",
    "variances = var(X_train_scaled, axis=0)\n",
    "high_var_indices = where(variances > 0.1)[0]\n",
    "X_train_high_var = X_train_scaled[:, high_var_indices]\n",
    "print(f\"Number of high variance features: {X_train_high_var.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79430df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 Transform but DO NOT fit the test features with the same steps applied in steps 11 and 12.\n",
    "\n",
    "# Transform but DO NOT fit the test features with min-max scaler and high variance selection\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_high_var = X_test_scaled[:, high_var_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38c74756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-value on high variance data: 0.6609\n",
      "RMSE on high variance data: 48644.2640\n"
     ]
    }
   ],
   "source": [
    "#15 Repeat step 7 with the high variance data.\n",
    "# Run a linear regression on high variance data\n",
    "model_high_var = LinearRegression()\n",
    "model_high_var.fit(X_train_high_var, y_train)\n",
    "\n",
    "# Evaluate the model on high variance test data\n",
    "y_pred_high_var = model_high_var.predict(X_test_high_var)\n",
    "r2_high_var = r2_score(y_test, y_pred_high_var)\n",
    "rmse_high_var = mean_squared_error(y_test, y_pred_high_var, squared=False)\n",
    "print(f\"R2-value on high variance data: {r2_high_var:.4f}\")\n",
    "print(f\"RMSE on high variance data: {rmse_high_var:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ce9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 Summarize your findings.\n",
    "\n",
    "## After preprocessing the data in the manner described above, there are two linear regressions on the training data, \n",
    "## one using the PCA-transformed data and another using the high variance data. The results are summarized below:\n",
    "\n",
    "## Linear regression using PCA-transformed data: R2-value = 0.7205, RMSE = 37992.1866\n",
    "## Linear regression using high variance data: R2-value = 0.7054, RMSE = 38846.3205\n",
    "## The model trained on PCA-transformed data performed slightly better than the one trained on \n",
    "## high variance data, as it has a higher R2-value and lower RMSE. \n",
    "## This could mean that the PCA transformation was able to capture the most important features \n",
    "## in the data and remove the noise. However, it is important to note that the difference \n",
    "## in performance between the two models is relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cb77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
